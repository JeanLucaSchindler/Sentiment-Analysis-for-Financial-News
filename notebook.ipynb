{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 18:51:16.289165: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-05 18:51:16.310782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 18:51:16.334390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 18:51:16.340402: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 18:51:16.358315: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 18:51:18.724438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/jeanluca/code/JeanLucaSchindler/Portfolio/Sentiment_Analysis/Sentiment-Analysis-for-Financial-News/raw_data/all-data.csv', encoding='ISO-8859-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={0:'sentiment', 1:'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'negative':0,\n",
    "          'neutral':1,\n",
    "          'positive':2\n",
    "          }\n",
    "\n",
    "def transform_labels(label):\n",
    "    return labels[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.sentiment.apply(transform_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['label']]\n",
    "\n",
    "X = data[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(X.to_numpy(),\n",
    "                                                                            y.to_numpy(),\n",
    "                                                                            test_size = 0.2,\n",
    "                                                                            random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening to ensure that each element is a string\n",
    "train_sentences = [sentence[0] for sentence in train_sentences]\n",
    "val_sentences = [sentence[0] for sentence in val_sentences]\n",
    "\n",
    "# Ensure labels are in the correct shape\n",
    "train_labels = train_labels.flatten()\n",
    "val_labels = val_labels.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi-class classification setup\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "class USELayerWithExpandDims(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(USELayerWithExpandDims, self).__init__(**kwargs)\n",
    "        self.use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        use_output = self.use(inputs)\n",
    "        return tf.expand_dims(use_output, axis=1)\n",
    "\n",
    "inputs = layers.Input(shape=(), dtype=tf.string, name=\"input_layer\")\n",
    "x = USELayerWithExpandDims()(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(72, return_sequences=True))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(72, return_sequences=True))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(72))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(3, activation='softmax', name='output_layer')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"model_lstm\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Ensure labels are one-hot encoded\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=3)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=3)\n",
    "\n",
    "# Convert datasets to include one-hot encoded labels\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 780ms/step - accuracy: 0.5826 - loss: 0.9802 - val_accuracy: 0.6649 - val_loss: 0.7014\n",
      "Epoch 2/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 615ms/step - accuracy: 0.6631 - loss: 0.7061 - val_accuracy: 0.7381 - val_loss: 0.6307\n",
      "Epoch 3/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 647ms/step - accuracy: 0.7295 - loss: 0.6289 - val_accuracy: 0.7557 - val_loss: 0.5743\n",
      "Epoch 4/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 658ms/step - accuracy: 0.7707 - loss: 0.5531 - val_accuracy: 0.7680 - val_loss: 0.5423\n",
      "Epoch 5/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 636ms/step - accuracy: 0.7896 - loss: 0.5088 - val_accuracy: 0.7598 - val_loss: 0.5510\n",
      "Epoch 6/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 625ms/step - accuracy: 0.7955 - loss: 0.4896 - val_accuracy: 0.7660 - val_loss: 0.5461\n",
      "Epoch 7/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 634ms/step - accuracy: 0.7998 - loss: 0.4772 - val_accuracy: 0.7680 - val_loss: 0.5464\n",
      "Epoch 8/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 643ms/step - accuracy: 0.8072 - loss: 0.4596 - val_accuracy: 0.7711 - val_loss: 0.5464\n",
      "Epoch 9/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 641ms/step - accuracy: 0.7998 - loss: 0.4575 - val_accuracy: 0.7711 - val_loss: 0.5435\n",
      "Epoch 10/10\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 578ms/step - accuracy: 0.8162 - loss: 0.4436 - val_accuracy: 0.7711 - val_loss: 0.5454\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data = valid_dataset, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f636945a3e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 781ms/step\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = tf.round(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 280ms/step - accuracy: 0.7807 - loss: 0.5482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5454019904136658, 0.7711340188980103]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Define the custom layer class again\n",
    "# class USELayerWithExpandDims(tf.keras.layers.Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(USELayerWithExpandDims, self).__init__(**kwargs)\n",
    "#         self.use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         use_output = self.use(inputs)\n",
    "#         return tf.expand_dims(use_output, axis=1)\n",
    "\n",
    "# # Load the model, ensuring the custom layer is registered\n",
    "# model = load_model('/home/jeanluca/code/JeanLucaSchindler/Portfolio/Sentiment_Analysis/Sentiment-Analysis-for-Financial-News/best_model.h5', custom_objects={'USELayerWithExpandDims': USELayerWithExpandDims})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = [\n",
    "    # Positive News\n",
    "    \"Tech company reports record profits for the second quarter in a row.\",\n",
    "    \"New partnership announcement boosts company's stock price by 15%.\",\n",
    "    \"Startup secures major investment, plans to expand globally.\",\n",
    "    \"The new product launch has been a tremendous success, receiving rave reviews.\",\n",
    "\n",
    "    # Negative News\n",
    "    \"Shares plummet as the company faces allegations of financial misconduct.\",\n",
    "    \"Company announces major layoffs due to declining sales.\",\n",
    "    \"The market reacts negatively to the disappointing earnings report.\",\n",
    "    \"Product recall issued due to safety concerns.\",\n",
    "\n",
    "    # Neutral News\n",
    "    \"The CEO will present the company's new strategy at the upcoming conference.\",\n",
    "    \"The annual shareholder meeting is scheduled for next month.\",\n",
    "    \"Company releases its new range of eco-friendly products.\",\n",
    "    \"Board of directors announces the appointment of a new CFO.\",\n",
    "\n",
    "    # Mixed or Ambiguous Sentiments\n",
    "    \"While the new product received mixed reviews, initial sales figures are strong.\",\n",
    "    \"The company's revenue grew, but profit margins are shrinking due to rising costs.\",\n",
    "    \"Investors are cautious after the merger announcement, with some expecting market volatility.\",\n",
    "    \"Despite the strong market position, the company's future remains uncertain due to regulatory challenges.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.from_tensor_slices((custom, None)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08, 0.46, 0.46],\n",
       "       [0.  , 0.46, 0.54],\n",
       "       [0.  , 0.41, 0.59],\n",
       "       [0.  , 0.03, 0.97],\n",
       "       [0.84, 0.13, 0.02],\n",
       "       [0.85, 0.06, 0.09],\n",
       "       [0.88, 0.04, 0.08],\n",
       "       [0.63, 0.3 , 0.07],\n",
       "       [0.  , 0.98, 0.02],\n",
       "       [0.  , 0.99, 0.01],\n",
       "       [0.  , 0.72, 0.28],\n",
       "       [0.  , 0.94, 0.06],\n",
       "       [0.01, 0.15, 0.84],\n",
       "       [0.55, 0.03, 0.42],\n",
       "       [0.07, 0.9 , 0.03],\n",
       "       [0.86, 0.09, 0.06]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.round(pred, 2)\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
